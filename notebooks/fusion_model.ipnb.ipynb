{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b511d879",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daba3371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk; nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3089055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pandas as pd\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from torchvision.datasets.utils import download_url\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3292d658",
   "metadata": {},
   "source": [
    "## Step 1: Load Flickr30k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db0275d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_dir = \"../data/flickr30k_images\"\n",
    "flickr_captions_path = \"../data/captions.txt\"  # Modify if using JSON\n",
    "\n",
    "flickr_data = []\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "with open(flickr_captions_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if len(parts) < 2: continue\n",
    "        img, caption = parts\n",
    "        sentiment = sia.polarity_scores(caption)['compound']\n",
    "        label = \"positive\" if sentiment > 0.2 else \"negative\" if sentiment < -0.2 else \"neutral\"\n",
    "        flickr_data.append({\n",
    "            \"image_path\": os.path.join(flickr_dir, img),\n",
    "            \"caption\": caption,\n",
    "            \"text_sentiment\": label,\n",
    "            \"image_sentiment\": \"neutral\",  # Will use CLIP later\n",
    "            \"source\": \"flickr\"\n",
    "        })\n",
    "\n",
    "df_flickr = pd.DataFrame(flickr_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c8bfa",
   "metadata": {},
   "source": [
    "## STEP 2: Load Memotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6db121e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m df_memotion_raw.iterrows():\n\u001b[32m      8\u001b[39m     text = row[\u001b[33m'\u001b[39m\u001b[33mtext_corrected\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtext_corrected\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m row \u001b[38;5;28;01melse\u001b[39;00m row[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     sentiment = \u001b[43msia\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpolarity_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mcompound\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     10\u001b[39m     label = \u001b[33m\"\u001b[39m\u001b[33mpositive\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sentiment > \u001b[32m0.2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnegative\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sentiment < -\u001b[32m0.2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mneutral\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m     memotion_data.append({\n\u001b[32m     12\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mimage_path\u001b[39m\u001b[33m\"\u001b[39m: os.path.join(memotion_dir, row[\u001b[33m'\u001b[39m\u001b[33mimage_name\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcaption\u001b[39m\u001b[33m\"\u001b[39m: text,\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msource\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mmemotion\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m     })\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Projects\\PEER_HIVE_DS\\peerhive-env\\Lib\\site-packages\\nltk\\sentiment\\vader.py:366\u001b[39m, in \u001b[36mSentimentIntensityAnalyzer.polarity_scores\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[33;03mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[32m    357\u001b[39m \u001b[33;03mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m \u001b[33;03m    matched as if it was a normal word in the sentence.\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m sentitext = \u001b[43mSentiText\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPUNC_LIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mREGEX_REMOVE_PUNCTUATION\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m sentiments = []\n\u001b[32m    370\u001b[39m words_and_emoticons = sentitext.words_and_emoticons\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Hp\\Projects\\PEER_HIVE_DS\\peerhive-env\\Lib\\site-packages\\nltk\\sentiment\\vader.py:270\u001b[39m, in \u001b[36mSentiText.__init__\u001b[39m\u001b[34m(self, text, punc_list, regex_remove_punctuation)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text, punc_list, regex_remove_punctuation):\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         text = \u001b[38;5;28mstr\u001b[39m(\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m    271\u001b[39m     \u001b[38;5;28mself\u001b[39m.text = text\n\u001b[32m    272\u001b[39m     \u001b[38;5;28mself\u001b[39m.PUNC_LIST = punc_list\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "memotion_dir = \"../data/Memotion_Dataset/memes\"\n",
    "memotion_labels_path = \"../data/Memotion_Dataset/labels.csv\"\n",
    "\n",
    "df_memotion_raw = pd.read_csv(memotion_labels_path)\n",
    "\n",
    "memotion_data = []\n",
    "for _, row in df_memotion_raw.iterrows():\n",
    "    text = row['text_corrected'] if 'text_corrected' in row else row['text']\n",
    "    sentiment = sia.polarity_scores(text)['compound']\n",
    "    label = \"positive\" if sentiment > 0.2 else \"negative\" if sentiment < -0.2 else \"neutral\"\n",
    "    memotion_data.append({\n",
    "        \"image_path\": os.path.join(memotion_dir, row['image_name']),\n",
    "        \"caption\": text,\n",
    "        \"text_sentiment\": label,\n",
    "        \"image_sentiment\": row.get(\"overall_sentiment\", \"unknown\"),\n",
    "        \"humor\": row.get(\"humour\", 0),\n",
    "        \"sarcasm\": row.get(\"sarcasm\", 0),\n",
    "        \"offensive\": row.get(\"offensive\", 0),\n",
    "        \"motivation\": row.get(\"motivational\", 0),\n",
    "        \"source\": \"memotion\"\n",
    "    })\n",
    "\n",
    "df_memotion = pd.DataFrame(memotion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafb6e0",
   "metadata": {},
   "source": [
    "## ðŸ§¬ STEP 3: Normalize columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67ef7c",
   "metadata": {},
   "source": [
    "shared_cols = ['image_path', 'caption', 'text_sentiment', 'image_sentiment', 'source']\n",
    "df_memotion = df_memotion[shared_cols + ['humor', 'sarcasm', 'offensive', 'motivation']]\n",
    "df_flickr = df_flickr[shared_cols]\n",
    "for col in ['humor', 'sarcasm', 'offensive', 'motivation']:\n",
    "    df_flickr[col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b7c38e",
   "metadata": {},
   "source": [
    "## ðŸ’¾ STEP 4: Merge + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a0d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fusion = pd.concat([df_flickr, df_memotion], ignore_index=True)\n",
    "df_fusion.to_csv(\"fusion_mood_dataset.csv\", index=False)\n",
    "print(\"âœ… Fusion dataset saved: fusion_mood_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "peerhive-env",
   "language": "python",
   "name": "peerhive-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
